from playwright.sync_api import sync_playwright, Playwright
from app.link_browser import edit_link
from app.html_generator import save_page
import json
import asyncio
import os


def trace_json(file_name: str) -> None:

    """

    This function may look odd.
    Trace file generated by browser is an object made from arrays.
    - traceEvents is the array which contains all the events including render and network operations
    - args is the array which contains the data about the event
    - data is the array which contains the data about the event located in args object
    - url is the key which contains the url of the asset file. It can be analytics or css/img/js file.

    All asset files are using renderBlocking key to get priority in fetch operation. By using this keyword we can detect
    all asset files. The url to fetch these datas are in the url key.

    In summary: The operation is loop through the traceEvents array and get the url key from the data object located in
    args object which has renderBlocking key.

    :param file_name: Name of the json file to detect assets
    :return: None

    """

    with open(f"chrome_traces/{file_name}", "r", encoding="utf-8") as f:
        data = json.load(f)
        f.close()
    urls = []

    # Loop in traceEvents array and get the url key from the data object located in args object has renderBlocking key
    for i in data['traceEvents']:
        try:
            # Some objects may not have args key or data key or renderBlocking key. So we need to check it.
            if "args" in i.keys() and "data" in i["args"].keys() and "renderBlocking" in i["args"]["data"].keys():
                urls.append(i["args"]["data"]["url"])
        except KeyError:
            print("Error for object: ", i)
    # download_assets(urls)
    with open("temp_data/asset_list.txt", "a", encoding="utf-8") as f:
        for url in urls:
            f.writelines(url + "\n")
        f.close()


def run(playwright: Playwright) -> None:

    """

    This will open the browser and go to the website and save the html file.
    All operations are running under the same browser instance.

    :param playwright: Instance to run Playwright
    :return:

    """

    print("\033[0;35m Running playwright for crawling \033[0m")
    browser = playwright.chromium.launch(headless=True, slow_mo=50)
    context = browser.new_context()
    page = context.new_page()

    # Crate trace to detect asset files
    browser.start_tracing(page=page, path="chrome_traces/home.json", categories=["devtools.timeline"])
    page.goto("https://www.classcentral.com")
    page.wait_for_load_state("load", timeout=0)
    browser.stop_tracing()

    # Save the HTML file for home page
    print("\033[0;35m Generating HTML file \033[0m")
    asyncio.create_task(save_page(page.content(), "index", 1))

    # Run function to detect assets and download them
    print("\033[0;35m Extracting assets \033[0m")
    trace_json("home.json")

    # Print all links in the page to file
    link_list = [x.get_attribute("href") for x in page.locator("a").all()]
    with open("temp_data/links.txt", "w", encoding="utf-8") as f:
        for link in link_list:
            f.write(link + "\n")
        f.close()

    edit_link()

    # Visit the links and save the html files
    url_list = []
    with open("temp_data/links_new.txt", "r", encoding="utf-8") as f:
        url_list = f.readlines()
        f.close()

    for link in url_list:
        if "https://www.classcentral.com/" in link:
            custom_link = link.replace("\n", "").replace(" ", "").rstrip('/').split('/')
            print(f"The link has {len(custom_link)} parts and the link is {custom_link}")
            link_folder = custom_link[-2]
            link_file = custom_link[-1]
            if len(custom_link) == 5:
                page = context.new_page()
                browser.start_tracing(page=page, path=f"chrome_traces/{link_folder}/{link_file}.json",
                                      categories=["devtools.timeline"])

                page.goto(link)
                page.wait_for_load_state("load", timeout=0)
                browser.stop_tracing()
                asyncio.create_task(save_page(page.content(), f"{link_folder}/{link_file}", 2))
                trace_json(f"{link_folder}/{link_file}.json")
            elif len(custom_link) == 4:
                page = context.new_page()
                browser.start_tracing(page=page, path=f"chrome_traces/{link_file}.json",
                                      categories=["devtools.timeline"])
                page.goto(link)
                page.wait_for_load_state("load", timeout=0)
                browser.stop_tracing()
                asyncio.create_task(save_page(page.content(), f"{link_file}", 1))
                trace_json(f"{link_file}.json")
            elif len(custom_link) == 6:
                page = context.new_page()
                browser.start_tracing(page=page, path=f"chrome_traces/{custom_link[-3]}/{link_folder}/{link_file}.json",
                                      categories=["devtools.timeline"])
                page.goto(link)
                page.wait_for_load_state("load", timeout=0)
                browser.stop_tracing()
                asyncio.create_task(save_page(page.content(), f"{custom_link[-3]}/{link_folder}/{link_file}", 3))
                trace_json(f"{custom_link[-3]}/{link_folder}/{link_file}.json")
            else:
                continue
            page.wait_for_timeout(3000)
            page.close()
    print("Everything is done. Closing the browser.")
    context.close()
    browser.close()



with sync_playwright() as p:
    run(p)
